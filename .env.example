# ============================================
# LLM Backend Configuration
# ============================================
# Options: "openrouter" (remote API) or "ollama" (local models)
LLM_BACKEND=openrouter

# OpenRouter API Configuration (Remote LLMs)
# Get your API key from: https://openrouter.ai/keys
OPENROUTER_API_KEY=your-api-key-here
OPENROUTER_MODEL=anthropic/claude-3.5-sonnet

# Ollama Configuration (Local LLMs)
# Install Ollama from: https://ollama.ai
# Then run: ollama pull llama3.2
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# ============================================
# ChromaDB Configuration
# ============================================
CHROMA_PERSIST_DIR=./chroma_db

# ============================================
# Embedding & NLP Models
# ============================================
# Embedding Model (GPU-accelerated: MPS on Mac, CUDA on Windows/Linux)
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Sentiment Analysis Model (RoBERTa)
# 11-emotion model: joy, love, optimism, trust, anticipation, anger, disgust, fear, sadness, pessimism, surprise
SENTIMENT_MODEL=cardiffnlp/twitter-roberta-base-emotion-multilabel-latest

# spaCy Model for NER and linguistic analysis
# Options: en_core_web_sm (fast), en_core_web_md (better), en_core_web_lg (best)
SPACY_MODEL=en_core_web_md

# ============================================
# Memory Settings
# ============================================
MAX_MEMORY_ITEMS=1000
MEMORY_RELEVANCE_THRESHOLD=0.3

# ============================================
# Performance & Warning Suppression
# ============================================
# Suppress HuggingFace tokenizers fork warning
TOKENIZERS_PARALLELISM=false
